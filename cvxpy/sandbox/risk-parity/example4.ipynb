{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a99712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of information technology stocks: 68\n",
      "Number of healthcare stocks: 60\n",
      "Number of financials stocks: 75\n",
      "Number of consumer discretionary stocks: 50\n",
      "Number of industrials stocks: 79\n"
     ]
    }
   ],
   "source": [
    "# Load the GICS sector information from the CSV file\n",
    "df = pd.read_csv(\"sp500_gics_sectors.csv\", index_col=0)\n",
    "information_technology_stocks = list(df[df[\"GICS Sector\"] == \"Information Technology\"].index)\n",
    "healthcare_stocks = list(df[df[\"GICS Sector\"] == \"Health Care\"].index)\n",
    "financials_stocks = list(df[df[\"GICS Sector\"] == \"Financials\"].index)\n",
    "consumer_discretionary_stocks = list(df[df[\"GICS Sector\"] == \"Consumer Discretionary\"].index)\n",
    "industrials_stocks = list(df[df[\"GICS Sector\"] == \"Industrials\"].index)\n",
    "\n",
    "print(\"Number of information technology stocks:\", len(information_technology_stocks))\n",
    "print(\"Number of healthcare stocks:\", len(healthcare_stocks))\n",
    "print(\"Number of financials stocks:\", len(financials_stocks))\n",
    "print(\"Number of consumer discretionary stocks:\", len(consumer_discretionary_stocks))\n",
    "print(\"Number of industrials stocks:\", len(industrials_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b019ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206876/3216576327.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=\"2020-01-01\", end=\"2025-01-01\")\n",
      "[*********************100%***********************]  332 of 332 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    }
   ],
   "source": [
    "# download return data\n",
    "tickers = information_technology_stocks + healthcare_stocks + financials_stocks + \\\n",
    "          consumer_discretionary_stocks + industrials_stocks\n",
    "data = yf.download(tickers, start=\"2020-01-01\", end=\"2025-01-01\")\n",
    "data = data.dropna(axis=1, how='any')\n",
    "returns = data['Close'].pct_change().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f39a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of information technology stocks: 66\n",
      "Number of healthcare stocks: 58\n",
      "Number of financials stocks: 72\n",
      "Number of consumer discretionary stocks: 48\n",
      "Number of industrials stocks: 75\n"
     ]
    }
   ],
   "source": [
    "# remove sector indices of stocks with no data\n",
    "information_technology_stocks = [stock for stock in information_technology_stocks if\n",
    "                                 stock in returns.columns]\n",
    "healthcare_stocks = [stock for stock in healthcare_stocks if stock in returns.columns]\n",
    "financials_stocks = [stock for stock in financials_stocks if stock in returns.columns]\n",
    "consumer_discretionary_stocks = [stock for stock in consumer_discretionary_stocks if \n",
    "                                 stock in returns.columns]\n",
    "industrials_stocks = [stock for stock in industrials_stocks if stock in returns.columns]\n",
    "\n",
    "print(\"Number of information technology stocks:\", len(information_technology_stocks))\n",
    "print(\"Number of healthcare stocks:\", len(healthcare_stocks))\n",
    "print(\"Number of financials stocks:\", len(financials_stocks))\n",
    "print(\"Number of consumer discretionary stocks:\", len(consumer_discretionary_stocks))\n",
    "print(\"Number of industrials stocks:\", len(industrials_stocks))\n",
    "\n",
    "# choose the stocks in the sectors \n",
    "returns = returns[information_technology_stocks + healthcare_stocks + financials_stocks + \n",
    "                   consumer_discretionary_stocks + industrials_stocks]\n",
    "\n",
    "idxs_info_tech = [i for i, stock in enumerate(returns.columns) if stock in \n",
    "                  information_technology_stocks]\n",
    "idxs_healthcare = [i for i, stock in enumerate(returns.columns) if stock in healthcare_stocks]\n",
    "idxs_financials = [i for i, stock in enumerate(returns.columns) if stock in financials_stocks]\n",
    "idxs_consumer_discretionary = [i for i, stock in enumerate(returns.columns) if stock in \n",
    "                               consumer_discretionary_stocks]\n",
    "idxs_industrials = [i for i, stock in enumerate(returns.columns) if stock in industrials_stocks]\n",
    "\n",
    "groups = [idxs_info_tech, idxs_healthcare, idxs_financials, idxs_consumer_discretionary, \n",
    "          idxs_industrials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c93a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest and largest eigenvalues of Sigma: 0.00012248218116280238 0.06136787550647771\n"
     ]
    }
   ],
   "source": [
    "# compute the covariance matrix and regularize it\n",
    "Sigma = returns.cov().values\n",
    "n = Sigma.shape[0]\n",
    "alpha = 0.8\n",
    "Sigma = alpha * Sigma + (1-alpha) * np.trace(Sigma) / n * np.eye(n)\n",
    "evals = np.linalg.eigvalsh(Sigma)\n",
    "print(\"smallest and largest eigenvalues of Sigma:\", min(evals), max(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68221a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify risk contributions\n",
    "b = np.ones(len(groups)) / len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8abda7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc0c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Oct 03 04:04:30 PM: Your problem has 638 variables, 320 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 03 04:04:30 PM: It is compliant with the following grammars: \n",
      "(CVXPY) Oct 03 04:04:30 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 03 04:04:30 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Oct 03 04:04:30 PM: Your problem is compiled with the CPP canonicalization backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                             v1.7.0.dev0+0.5870139                             \n",
      "===============================================================================\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.11.9, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:   107209\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:    51688\n",
      "\n",
      "Total number of variables............................:     1929\n",
      "                     variables with only lower bounds:      329\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:     1611\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  2.8308120e+04 5.56e+01 1.00e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  2.7076704e+04 5.32e+01 8.77e+01  -0.2 5.60e+03    -  1.00e+00 4.40e-02f  1\n",
      "   2  2.9155908e+04 5.21e+01 7.12e+03   2.4 3.22e+04    -  1.44e-01 1.29e-02h  1\n",
      "   3  2.9779409e+04 5.14e+01 2.83e+04   2.1 1.02e+04    -  1.00e+00 1.22e-02f  1\n",
      "   4  2.9518030e+04 3.39e+01 1.80e+04   1.3 1.53e+02    -  1.00e+00 3.41e-01h  1\n",
      "   5  2.9177127e+04 3.39e-01 3.45e+03   0.2 6.88e+01  -2.0 1.00e+00 9.91e-01h  1\n",
      "   6  2.9177126e+04 2.55e-01 6.46e+04   0.7 2.47e-01   2.9 1.00e+00 2.48e-01f  1\n",
      "   7  2.9178227e+02 9.34e-03 9.75e+08   2.0 5.44e+05    -  1.32e-02 1.06e-02f  1\n",
      "   8  2.9178195e+02 6.32e-03 6.60e+08   0.4 3.47e-01   3.4 1.00e+00 3.23e-01f  1\n",
      "   9  2.9178199e+02 6.24e-03 6.52e+08  -5.8 3.53e+00   2.9 1.98e-03 1.27e-02h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r 2.9178199e+02 6.24e-03 1.00e+03  -2.2 0.00e+00   2.4 0.00e+00 4.00e-07R  8\n",
      "  11r 2.9177998e+02 3.36e-03 1.32e+03  -2.1 6.16e+00    -  1.00e+00 1.00e-03f  1\n",
      "  12  2.9225885e+00 1.54e-03 1.32e+03   0.2 2.75e+04    -  2.48e-03 2.10e-03f  1\n",
      "  13  2.9113047e+00 1.41e-03 8.16e+02  -1.3 1.27e-01   1.9 1.00e+00 8.49e-02f  1\n",
      "  14  3.2253070e-02 6.61e-04 3.56e+03  -1.4 1.09e+00    -  1.00e+00 5.32e-01f  1\n",
      "  15  8.1565002e-04 3.17e-04 1.70e+03  -2.9 1.24e-02   1.5 1.00e+00 5.21e-01h  1\n",
      "  16  4.3579371e-04 2.84e-04 1.52e+03  -4.4 7.92e-04   1.9 1.00e+00 1.05e-01h  1\n",
      "  17  4.2660049e-04 2.83e-04 2.08e+03  -4.1 6.49e-03   2.3 1.00e+00 3.59e-03h  1\n",
      "  18  3.7405892e-05 2.39e-04 1.28e+03  -3.7 1.17e-02   1.8 1.00e+00 1.56e-01h  1\n",
      "  19  2.6844318e-05 2.37e-04 1.69e+04  -2.9 2.21e-02   2.3 1.00e+00 7.89e-03h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20 -3.8721345e-05 2.18e-04 2.62e+04  -1.9 8.14e-02   1.8 1.00e+00 7.82e-02h  1\n",
      "  21 -6.1653048e-05 1.74e-04 4.58e+03  -1.1 4.67e-01    -  5.02e-02 1.88e-01h  1\n",
      "  22 -9.4654272e-05 9.62e-05 5.33e+03  -7.9 2.25e-01   1.3 1.64e-01 4.40e-01h  1\n",
      "  23 -9.3504324e-05 4.02e-07 5.71e+03  -2.8 1.41e-02   1.7 1.00e+00 1.00e+00f  1\n",
      "  24 -7.4262336e-05 7.37e-06 1.19e+04  -2.3 7.30e-02   1.3 1.00e+00 4.32e-01f  1\n",
      "  25 -7.3166750e-05 1.28e-05 1.16e+04  -2.4 1.14e+00    -  2.01e-02 5.95e-02f  1\n",
      "  26 -5.3967478e-05 1.79e-05 5.91e+03  -2.4 1.73e-01    -  9.51e-02 5.24e-01f  1\n",
      "  27 -5.3991597e-05 1.80e-05 5.97e+03  -2.4 4.26e+00    -  1.34e-04 2.52e-03f  2\n",
      "  28 -4.6804028e-05 1.53e-05 5.88e+03  -2.4 6.13e-02   0.8 3.82e-01 2.07e-01f  1\n",
      "  29 -3.9966819e-05 1.35e-05 7.83e+03  -2.4 1.28e-01   0.3 6.48e-01 2.28e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30 -3.9396425e-05 1.31e-05 3.40e+03  -2.4 2.98e-01    -  5.75e-01 1.47e-01f  1\n",
      "  31 -3.9375812e-05 1.31e-05 3.40e+03  -2.4 1.68e+00  -0.2 1.66e-03 2.22e-03f  2\n",
      "  32 -3.3808368e-05 1.15e-05 3.64e+03  -2.4 1.05e-01   0.2 5.97e-01 2.51e-01f  1\n",
      "  33 -2.5949895e-05 9.10e-06 4.27e+03  -2.4 8.48e-02    -  1.00e+00 2.98e-01f  1\n",
      "  34 -1.7642664e-05 6.43e-06 2.85e+03  -2.4 5.19e-02    -  3.30e-01 3.43e-01f  1\n",
      "  35  3.2422169e-06 4.24e-07 5.51e+03  -2.4 5.53e-03    -  6.66e-01 1.00e+00f  1\n",
      "  36  9.0065296e-07 1.69e-07 6.51e+02  -2.4 2.28e-03    -  1.00e+00 1.00e+00f  1\n",
      "  37  1.5490520e-06 2.24e-11 4.81e+00  -3.0 1.06e-04    -  1.00e+00 1.00e+00h  1\n",
      "  38  1.5474055e-06 1.36e-13 5.00e-03  -5.1 1.97e-06    -  1.00e+00 1.00e+00h  1\n",
      "  39  1.4031346e-06 1.44e-09 4.43e-03  -5.2 2.07e-04    -  1.00e+00 1.00e+00h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  40  1.3267704e-06 2.75e-10 5.38e-03  -6.7 6.16e-05    -  1.00e+00 1.00e+00h  1\n",
      "  41 -1.7269180e-07 9.43e-08 1.56e-03  -7.3 2.56e-03    -  1.00e+00 1.00e+00h  1\n",
      "  42 -3.2178596e-09 7.45e-08 1.28e-03  -7.8 1.94e-02    -  9.69e-01 1.00e+00H  1\n",
      "  43 -7.5829813e-09 1.33e-09 2.43e-05  -9.0 4.70e-04    -  1.00e+00 1.00e+00h  1\n",
      "Time spent in Jacobian evaluations:  2.71299409866333\n",
      "Time spent in Hessian evaluations:   19.883847951889038\n",
      "  44 -1.1630227e-10 3.38e-11 5.14e-07 -11.0 8.01e-05    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 44\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -1.1630226982346651e-10   -1.1630226982346651e-10\n",
      "Dual infeasibility......:   5.1364235831297123e-07    5.1364235831297123e-07\n",
      "Constraint violation....:   3.3751375311122725e-11    3.3751375311122725e-11\n",
      "Complementarity.........:   1.6704037976572438e-11    1.6704037976572438e-11\n",
      "Overall NLP error.......:   6.3682570608453469e-08    5.1364235831297123e-07\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 59\n",
      "Number of objective gradient evaluations             = 45\n",
      "Number of equality constraint evaluations            = 59\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 47\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 44\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      4.513\n",
      "Total CPU secs in NLP function evaluations           =     21.212\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(8.602175232980819e-15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1 = 0\n",
    "term2 = 0\n",
    "term3 = 0\n",
    "\n",
    "w = cp.Variable((n, ), nonneg=True, name='w')\n",
    "t = cp.Variable((n, ), name='t')\n",
    "constraints = [cp.sum(w) == 1, t == Sigma @ w]\n",
    "\n",
    "w.value = np.random.rand(n)\n",
    "w.value = w.value / np.sum(w.value)\n",
    "#w.value = np.ones(n) / n\n",
    "\n",
    "for k, g in enumerate(groups):\n",
    "    term1 += cp.square(cp.sum(cp.multiply(w[g], t[g]))) /  cp.quad_form(w, Sigma)\n",
    "    term2 += (LA.norm(b[k]) ** 2) * cp.quad_form(w, Sigma)\n",
    "    term3 += - 2 * b[k] * cp.sum(cp.multiply(w[g], t[g]))\n",
    "obj = cp.Minimize(term1 + term2 + term3)\n",
    "problem = cp.Problem(obj, constraints)\n",
    "problem.solve(solver=cp.IPOPT, nlp=True, verbose=True, derivative_test='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10bdbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_contributions = w.value * (Sigma @ w.value) \n",
    "risk_contributions /= np.sum(risk_contributions)\n",
    "risk_contributions = np.array([np.sum(risk_contributions[g]) for g in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a9a149",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Step 1: Download the list of S&P 500 companies and their GICS sectors from Wikipedia\u001b[39;00m\n\u001b[32m      5\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://en.wikipedia.org/wiki/List_of_S\u001b[39m\u001b[33m%\u001b[39m\u001b[33m26P_500_companies\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tables = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df = tables[\u001b[32m0\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Step 2: Filter the dataframe to include only the 'Symbol' and 'GICS Sector' columns\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#df = df[['Symbol', 'GICS Sector']]\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#print(data_clean.head())\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#print(sector_info.head())\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/html.py:983\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m p = parser(\n\u001b[32m    973\u001b[39m     io,\n\u001b[32m    974\u001b[39m     compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m     storage_options,\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     tables = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[32m    986\u001b[39m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[33m\"\u001b[39m\u001b[33mseekable\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io.seekable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/html.py:249\u001b[39m, in \u001b[36m_HtmlFrameParser.parse_tables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     tables = \u001b[38;5;28mself\u001b[39m._parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.match, \u001b[38;5;28mself\u001b[39m.attrs)\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/html.py:806\u001b[39m, in \u001b[36m_LxmlFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    804\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[33m\"\u001b[39m\u001b[33mtext_content\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/html.py:785\u001b[39m, in \u001b[36m_LxmlFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m.io):\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    788\u001b[39m             r = parse(f.handle, parser=parser)\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    790\u001b[39m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/2025/nonconvex-modeling/code/venv/lib/python3.12/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Download the list of S&P 500 companies and their GICS sectors from Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0]\n",
    "\n",
    "# Step 2: Filter the dataframe to include only the 'Symbol' and 'GICS Sector' columns\n",
    "#df = df[['Symbol', 'GICS Sector']]\n",
    "\n",
    "# Step 3: Download historical adjusted closing prices for the top 400 stocks from 2020-2025\n",
    "#tickers = df['Symbol'].head(400).tolist()\n",
    "#data = yf.download(tickers, start='2020-01-01', end='2025-12-31')['Adj Close']\n",
    "\n",
    "# Step 4: Remove any stocks with missing data\n",
    "#data_clean = data.dropna(axis=1, how='any')\n",
    "\n",
    "# Step 5: Merge the cleaned data with the GICS sector information\n",
    "#sector_info = df.set_index('Symbol').loc[data_clean.columns]\n",
    "#sector_info = sector_info.rename(columns={'GICS Sector': 'Sector'})\n",
    "\n",
    "# Step 6: Save the GICS sector information to a CSV file\n",
    "#sector_info.to_csv('sp500_gics_sectors.csv')\n",
    "\n",
    "# Display the first few rows of the cleaned data and sector information\n",
    "#print(data_clean.head())\n",
    "#print(sector_info.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc788a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
